{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68041e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer    \n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MaxAbsScaler,Binarizer\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, StackingClassifier, HistGradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV, KFold, RepeatedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.linear_model import LogisticRegressionCV, RidgeCV, LassoCV\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LassoCV\n",
    "from sklearn.svm import SVC\n",
    "from IPython.display import clear_output\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbPipeline\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from skmultilearn.model_selection import IterativeStratification,iterative_stratification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from optuna.integration import LightGBMPruningCallback\n",
    "from IPython.display import clear_output\n",
    "from category_encoders import TargetEncoder, CatBoostEncoder, HelmertEncoder, MEstimateEncoder\n",
    "# from category_encoders.one_hot import OneHotEncoder\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from scipy.optimize import fmin, differential_evolution\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy.special import softmax\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654f6409",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv')\n",
    "original = pd.read_csv('data/original.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66c06ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   UDI                      10000 non-null  int64  \n",
      " 1   Product ID               10000 non-null  object \n",
      " 2   Type                     10000 non-null  object \n",
      " 3   Air temperature [K]      10000 non-null  float64\n",
      " 4   Process temperature [K]  10000 non-null  float64\n",
      " 5   Rotational speed [rpm]   10000 non-null  int64  \n",
      " 6   Torque [Nm]              10000 non-null  float64\n",
      " 7   Tool wear [min]          10000 non-null  int64  \n",
      " 8   Machine failure          10000 non-null  int64  \n",
      " 9   TWF                      10000 non-null  int64  \n",
      " 10  HDF                      10000 non-null  int64  \n",
      " 11  PWF                      10000 non-null  int64  \n",
      " 12  OSF                      10000 non-null  int64  \n",
      " 13  RNF                      10000 non-null  int64  \n",
      "dtypes: float64(3), int64(9), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "original.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "874906cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146429, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([\n",
    "                      data.drop(columns=['id']), \n",
    "                      original.drop(columns=['UDI']),                   \n",
    "                     ], \n",
    "                     ignore_index = True)\n",
    "new_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f7c871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 146429 entries, 0 to 146428\n",
      "Data columns (total 13 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Product ID               146429 non-null  object \n",
      " 1   Type                     146429 non-null  object \n",
      " 2   Air temperature [K]      146429 non-null  float64\n",
      " 3   Process temperature [K]  146429 non-null  float64\n",
      " 4   Rotational speed [rpm]   146429 non-null  int64  \n",
      " 5   Torque [Nm]              146429 non-null  float64\n",
      " 6   Tool wear [min]          146429 non-null  int64  \n",
      " 7   Machine failure          146429 non-null  int64  \n",
      " 8   TWF                      146429 non-null  int64  \n",
      " 9   HDF                      146429 non-null  int64  \n",
      " 10  PWF                      146429 non-null  int64  \n",
      " 11  OSF                      146429 non-null  int64  \n",
      " 12  RNF                      146429 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(2)\n",
      "memory usage: 14.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# new_data = data\n",
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5548a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d5e43c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air temperature [K]</th>\n",
       "      <th>Process temperature [K]</th>\n",
       "      <th>Rotational speed [rpm]</th>\n",
       "      <th>Torque [Nm]</th>\n",
       "      <th>Tool wear [min]</th>\n",
       "      <th>Machine failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Product ID, Type, Air temperature [K], Process temperature [K], Rotational speed [rpm], Torque [Nm], Tool wear [min], Machine failure, TWF, HDF, PWF, OSF, RNF]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data[new_data['Air temperature [K]'] == 0.00 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a27d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data['Product ID'] = new_data['Product ID'].str.slice(start=1).astype(float)\n",
    "# new_data['Product ID'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dc9f5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.983014\n",
       "1    0.016986\n",
       "Name: Machine failure, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data['Machine failure'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f8fe4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = {0: 0.016986, 1: 0.983014}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dce27d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "\n",
    "        if col_type not in ['object', 'category', 'datetime64[ns, UTC]']:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52cbe090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = reduce_mem_usage(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f48c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_feature_names(data):\n",
    "    cleaned_columns = []\n",
    "    for column in data.columns:\n",
    "        cleaned_column = re.sub('[^A-Za-z0-9_]+', '', column)\n",
    "        cleaned_columns.append(cleaned_column)\n",
    "    data.columns = cleaned_columns\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c97ebf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c9eaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = clean_feature_names(new_data)\n",
    "# Fit and Transform new_data\n",
    "# Base_Prob = 0.0\n",
    "# # Calculate the mean of Machine.failure for each Product.ID\n",
    "# train_prob = new_data.groupby('ProductID')['Machinefailure'].mean().reset_index()\n",
    "# train_prob.columns = ['ProductID', 'prob']\n",
    "# # Merge the calculated means into the original dataframe\n",
    "# new_data = pd.merge(new_data, train_prob, on='ProductID', how='inner')\n",
    "# # Replace prob values less than or equal to 0.15 with Base_Prob\n",
    "# new_data['prob'] = np.where(new_data['prob'] <= 0.15, Base_Prob, new_data['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "78f7c8d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm',\n",
       "       'TorqueNm', 'Toolwearmin', 'Machinefailure', 'TWF', 'HDF', 'PWF', 'OSF',\n",
       "       'RNF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cdbbc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "253"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(new_data['Toolwearmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82689f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_data.drop(columns=['Machinefailure'])\n",
    "y = new_data['Machinefailure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a2895c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.87155591572123"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imb_ratio = float(np.sum(y == 0)) / np.sum(y==1)\n",
    "imb_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a62f9518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductID', 'Type', 'AirtemperatureK', 'ProcesstemperatureK',\n",
       "       'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'TWF', 'HDF', 'PWF',\n",
       "       'OSF', 'RNF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfd15c",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8620b6",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">Light GBM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "014d3f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgb_best_params = \n",
    "#                   {'n_estimators': 608, \n",
    "#                    'learning_rate': 0.008786927731607481, \n",
    "#                    'max_depth': 10, \n",
    "#                    'num_leaves': 963, \n",
    "#                    'subsample': 0.5404369780011518, \n",
    "#                    'colsample_bytree': 0.507815726575903,\n",
    "#                    'is_unbalance' : True, \n",
    "#                    'metric' : 'auc'\n",
    "#                   }\n",
    "\n",
    "lgb_best_params = {\n",
    "                     'num_leaves': 64, \n",
    "                     'min_child_samples': 175, \n",
    "                     'max_depth': 18, \n",
    "                     'learning_rate': 0.013397950211504788, \n",
    "                     'colsample_bytree': 0.82, \n",
    "                     'n_estimators': 400, \n",
    "                     'reg_alpha': 4.798968170715771, \n",
    "                     'reg_lambda': 0.8001065724847404, \n",
    "                     'min_split_gain': 0.0227379006101743, \n",
    "                     'min_child_weight': 4.189021119554275, \n",
    "                     'subsample_freq': 2, \n",
    "                     'subsample': 0.7, \n",
    "                     'max_bin': 140,\n",
    "                     'categorical_feature' : [0,1],\n",
    "                   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1376a306",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">XGBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6720806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_params = { \n",
    "                    'n_estimators': 600,\n",
    "                    'max_depth': 6,\n",
    "                    'eval_metric' : 'auc',\n",
    "                    'lambda': 0.01, \n",
    "                    'alpha': 0.01, \n",
    "                    'colsample_bytree': 0.7, \n",
    "                    'subsample': 0.5, \n",
    "                    'learning_rate': 0.008, \n",
    "                    'min_child_weight': 1,\n",
    "                  }\n",
    "\n",
    "xgb_best_params1 = { 'tree_method':'gpu_hist',  # this parameter means using the GPU when training our model to speedup the training process\n",
    "                    'n_estimators': 800,\n",
    "                    'max_depth':7,\n",
    "                    'scale_pos_weight' : imb_ratio,\n",
    "                    'eval_metric' : 'auc',\n",
    "                    'lambda': 0.0005, \n",
    "                    'alpha': 0.028372243586991808, \n",
    "                    'colsample_bytree': 0.3944892085183995, \n",
    "                    'subsample': 0.840671541957931, \n",
    "                    'learning_rate': 0.01, \n",
    "                    'min_child_weight': 1,\n",
    "                    'predictor' : 'gpu_predictor'\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1ba25",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">CatBoost</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "840b467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cb_best_params= {'n_estimators': 361, \n",
    "#                  'learning_rate': 0.03732997222102321, \n",
    "#                  'max_depth': 8, \n",
    "#                  'subsample': 0.6959508889112623, \n",
    "#                  'colsample_bylevel': 0.5032559564347243,\n",
    "#                  'silent' : True,\n",
    "#                  'auto_class_weights': 'Balanced',\n",
    "#                  'eval_metric': 'AUC',\n",
    "#                  'random_strength': 43,\n",
    "#                 }\n",
    "\n",
    "cb_best_params = {   'iterations': 1200,\n",
    "                     'bootstrap_type': 'Bayesian',\n",
    "                     'depth': 1,\n",
    "                     'learning_rate': 0.08911870285993972,\n",
    "                     'random_strength': 82,\n",
    "                     'border_count': 210,\n",
    "                     'l2_leaf_reg': 8.928917322292204,\n",
    "                     'boosting_type': 'Ordered',\n",
    "                     'bagging_temperature': 7.167555149152137,\n",
    "                     'silent' : True,\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64098fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgbc_best_params = {'learning_rate': 0.1862615382501618, \n",
    "                   'max_iter': 934, \n",
    "                   'max_depth': 5, \n",
    "                   'l2_regularization': 0.31942345884883905,\n",
    "                   'class_weight' : 'balanced'\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bee44bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [   'AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm',\n",
    "                   'TorqueNm', 'Toolwearmin', 'TWF', 'HDF', 'PWF', 'OSF', 'Temp_Diff',\n",
    "                   'Failure_Summary', 'AirtemperatureKSquared', 'AirtemperatureKCubed',\n",
    "                   'AirtemperatureKLog', 'ProcesstemperatureKSquared',\n",
    "                   'ProcesstemperatureKCubed', 'ProcesstemperatureKLog',\n",
    "                   'RotationalspeedrpmSquared', 'RotationalspeedrpmCubed',\n",
    "                   'RotationalspeedrpmLog', 'TorqueNmSquared', 'TorqueNmCubed',\n",
    "                   'TorqueNmLog', 'ToolwearminSquared', 'ToolwearminCubed',\n",
    "                   'ToolwearminLog'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74ee7270",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class CustomFeats(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, df, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, df, y=None):\n",
    "        df = df.copy()\n",
    "        df['Temp_Diff'] = df['AirtemperatureK'] - df['ProcesstemperatureK']\n",
    "#         df['RotationalSpeed_TorqueRatio'] = df['Rotationalspeedrpm'] / df['TorqueNm']\n",
    "#         df['Power'] = df['TorqueNm'] * df['Rotationalspeedrpm']\n",
    "#         df['EfficiencyIndex'] = df['Power'] / df['Toolwearmin']\n",
    "\n",
    "#         # Calculate temperature difference\n",
    "#         df['TemperatureDifference'] = df['ProcesstemperatureK'] - df['AirtemperatureK']\n",
    "#         # Calculate temperature variability\n",
    "#         df['TemperatureVariability'] = df[['AirtemperatureK', 'ProcesstemperatureK']].std(axis=1)\n",
    "#         # Calculate temperature ratio\n",
    "#         df['TemperatureRatio'] = df['ProcesstemperatureK'] / df['AirtemperatureK']\n",
    "#         #Calculcating Average Temperature\n",
    "#         df['AverageTemperature'] = (df['ProcesstemperatureK'] + df['AirtemperatureK'])/2\n",
    "        \n",
    "#         # Calculate tool wear rate\n",
    "#         max_tool_wear = df['Toolwearmin'].max()\n",
    "#         df['ToolWearRate'] = df['Toolwearmin'] / max_tool_wear\n",
    "#         # Calculate temperature change rate\n",
    "#         df['TemperatureChangeRate'] = df['TemperatureDifference'] / (np.where(df['Toolwearmin']==0, 2,df['Toolwearmin']))\n",
    "#         df['Torque_ToolwearRatio'] = df['TorqueNm'] / (np.where(df['Toolwearmin']==0, 2,df['Toolwearmin']))\n",
    "\n",
    "        df['Failure_Summary'] = df[['TWF', 'HDF', 'PWF', 'OSF', 'RNF']].sum(axis=1)\n",
    "        \n",
    "        df = df.drop(['RNF'], axis =1)\n",
    "        \n",
    "        features_list = ['AirtemperatureK', 'ProcesstemperatureK', 'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin']\n",
    "        for feat in features_list:\n",
    "            df[f'{feat}Squared'] = df[feat] ** 2\n",
    "            df[f'{feat}Cubed'] = df[feat] ** 3\n",
    "            df[f'{feat}Log'] = df[feat].apply(lambda x: math.log(x) if x > 0 else 0)\n",
    "         \n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "802863cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_outliers(data):\n",
    "    for col in data[numeric_cols]:\n",
    "        Q1 = data[col].quantile(0.25)\n",
    "        Q3 = data[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower = Q1 - 1.5*IQR\n",
    "        upper = Q3 + 1.5*IQR\n",
    "        \n",
    "        if col not in ['Rotationalspeedrpm', 'Power']:\n",
    "            data[col] = np.clip(data[col], lower, upper)\n",
    "        else: \n",
    "            data[col] = np.clip(data[col], lower-200, upper+200)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3dba5bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, you can define your pipelines without 'custom_feats'\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "#     ('poly', PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)),\n",
    "    ('scaler', RobustScaler()),\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "#     ('encoder', OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ('encoder', CatBoostEncoder(cols = ['ProductID', 'Type'])),\n",
    "])\n",
    "\n",
    "# Update your preprocessor to use this pipeline for numerical and categorical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "#         ('num', num_pipe, numeric_cols),\n",
    "        ('cat', cat_pipe, ['ProductID', 'Type']),\n",
    "    ], remainder='passthrough')\n",
    "\n",
    "preprocessing_steps = [('Preprocessor', preprocessor)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a53809e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom_feats = CustomFeats()\n",
    "# X = custom_feats.fit_transform(X)\n",
    "# X.select_dtypes(exclude='O').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72b5d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features =  X.select_dtypes('O').columns\n",
    "for col in cat_features:\n",
    "    X[col] = X[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "209cb48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipes = []\n",
    "# Base Layer 1\n",
    "lgbm_pipe = Pipeline(steps=preprocessing_steps + [('lgbm', lgb.LGBMClassifier(**lgb_best_params))])\n",
    "model_pipes.append(lgbm_pipe)\n",
    "\n",
    "# Base Layer 2\n",
    "xgb_pipe = Pipeline(steps=preprocessing_steps + [('xgb', XGBClassifier(**xgb_best_params))])\n",
    "model_pipes.append(xgb_pipe)\n",
    "\n",
    "# # Base Layer 3\n",
    "cb_pipe = Pipeline(steps=preprocessing_steps + [('cb', CatBoostClassifier(**cb_best_params))])\n",
    "model_pipes.append(cb_pipe)\n",
    "\n",
    "# # # Base Layer 4\n",
    "# xgb_pipe1 = Pipeline(steps=preprocessing_steps + [('xgb2', XGBClassifier(**xgb_best_params1))])\n",
    "# model_pipes.append(xgb_pipe1)\n",
    "\n",
    "\n",
    "# # # Base Layer 5\n",
    "# brf_pipe = Pipeline(steps=preprocessing_steps + [('brf', BalancedRandomForestClassifier(  n_estimators=1000, \n",
    "#                                                                                            max_depth=None, \n",
    "#                                                                                            min_samples_split=2, \n",
    "#                                                                                            min_samples_leaf=1, \n",
    "#                                                                                            class_weight='balanced'))])\n",
    "# model_pipes.append(brf_pipe)\n",
    "\n",
    "# # Base Layer 6\n",
    "# hgbc_pipe = Pipeline(steps=preprocessing_steps + [('hgbc', HistGradientBoostingClassifier(**hgbc_best_params))])\n",
    "# model_pipes.append(hgbc_pipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5142e40",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">Blending to find the optimum CV</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "420c36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# This will suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f775caa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a47ad7d5",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 25px; color: #1192AA; text-align:left\">Blending</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd12f9",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">1. Averaging</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc251626",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">2. Rank Averaging </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4327c0",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">3. Weighted Averaging( calculated using f-min) </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9dfd2c",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">3. Weighted Averaging( calculated using Differential Evolution) </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5a20efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 25min 25s\n",
      "Wall time: 45min 46s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Weighted_Averaging</th>\n",
       "      <td>0.981711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Simple_Averaging</th>\n",
       "      <td>0.980495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank_Averaging</th>\n",
       "      <td>0.977979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Differential_Evolution</th>\n",
       "      <td>0.981493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Voting</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Mean_AUC\n",
       "Weighted_Averaging      0.981711\n",
       "Simple_Averaging        0.980495\n",
       "Rank_Averaging          0.977979\n",
       "Differential_Evolution  0.981493\n",
       "Voting                       NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "kf = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "\n",
    "# Initialize dictionary to hold AUC for each method\n",
    "auc_dict = {\n",
    "    \"Weighted_Averaging\": [],\n",
    "    \"Simple_Averaging\": [],\n",
    "    \"Rank_Averaging\": [],\n",
    "    \"Differential_Evolution\" : [] ,\n",
    "    'Voting' : [],\n",
    "}\n",
    "\n",
    "# Loop over folds\n",
    "for fold, (train_index, val_index) in enumerate(kf.split(X, y)):\n",
    "    print(f'Fold: {fold}')\n",
    "   \n",
    "    X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "    \n",
    "    # First apply the custom features to your data\n",
    "    custom_feats = CustomFeats()\n",
    "    X_train_fold = custom_feats.fit_transform(X_train_fold)\n",
    "    X_val_fold = custom_feats.transform(X_val_fold)\n",
    "\n",
    "    # replacing outliers\n",
    "#     X_train_fold = replace_outliers(X_train_fold)\n",
    "#     X_val_fold = replace_outliers(X_val_fold)\n",
    "        \n",
    "    pred_cols = []\n",
    "    optimized_base_models = []\n",
    "\n",
    "    # Create a new DataFrame for this fold\n",
    "    blended_df_fold = pd.DataFrame(index=range(len(X_val_fold)))\n",
    "\n",
    "    # Train each model on the current fold\n",
    "    for model_pipe in model_pipes:\n",
    "        model = list(model_pipe.named_steps.keys())[1]\n",
    "        print('Training model=', model, end=' ')\n",
    "        model_pipe.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Getting the name of the model        \n",
    "        model_name = model+'_valid_pred_fold_'+str(fold)\n",
    "        pred_cols.append(model_name)\n",
    "\n",
    "        # Store predictions for this fold\n",
    "        blended_df_fold[model_name] = model_pipe.predict_proba(X_val_fold)[:,1]\n",
    "        print(f'auc={roc_auc_score(y_val_fold, blended_df_fold[model_name])}')\n",
    "    \n",
    "    # Optimize weights on this fold using differential evolution\n",
    "    def objective_de(weights: np.ndarray):\n",
    "        weights = weights / np.sum(weights)  # Ensure weights are normalized\n",
    "        weighted_avg_preds = np.average(blended_df_fold[pred_cols].values, axis=1, weights=weights)\n",
    "        return -roc_auc_score(y_val_fold, weighted_avg_preds)\n",
    "    \n",
    "    # define bounds for differential_evolution\n",
    "    bounds = [(0,1)] * len(model_pipes)\n",
    "    result = differential_evolution(objective_de, bounds)\n",
    "    optimal_weights_de = result.x\n",
    "    optimal_weights_de = optimal_weights_de / np.sum(optimal_weights_de)  # Normalize weights\n",
    "    \n",
    "    # Add the differential evolution predictions to the DataFrame\n",
    "    blended_df_fold['diff_evolution_fold_'+str(fold)] = np.average(blended_df_fold[pred_cols].values, \n",
    "                                                                   axis=1, \n",
    "                                                                   weights=optimal_weights_de)\n",
    "\n",
    "    auc_diff_evolution = roc_auc_score(y_val_fold, blended_df_fold['diff_evolution_fold_'+str(fold)])\n",
    "    auc_dict[\"Differential_Evolution\"].append(auc_diff_evolution)\n",
    "    \n",
    "    # Optimize weights on this fold using F-Min\n",
    "    def objective(weights: np.ndarray):\n",
    "        weights = weights / np.sum(weights)  # Ensure weights are normalized\n",
    "        weighted_avg_preds = np.average(blended_df_fold[pred_cols].values, axis=1, weights=weights)\n",
    "        return -roc_auc_score(y_val_fold, weighted_avg_preds)\n",
    "\n",
    "    weights_init = np.array([1.0 / len(model_pipes)] * len(model_pipes))  # Initialize weights\n",
    "    optimal_weights = fmin(objective, weights_init, disp=True)  # Find weights that minimize the negative AUC\n",
    "    optimal_weights = optimal_weights / np.sum(optimal_weights)  # Normalize weights\n",
    "\n",
    "    # Add the weighted average predictions to the DataFrame\n",
    "    blended_df_fold['weighted_avg_fold_'+str(fold)] = np.average(blended_df_fold[pred_cols].values, \n",
    "                                                                 axis=1, \n",
    "                                                                 weights=optimal_weights)\n",
    "\n",
    "    auc_weighted_avg = roc_auc_score(y_val_fold, blended_df_fold['weighted_avg_fold_'+str(fold)])\n",
    "    auc_dict[\"Weighted_Averaging\"].append(auc_weighted_avg)\n",
    "\n",
    "    # Simple averaging\n",
    "    blended_df_fold['simple_avg_fold_'+str(fold)] = blended_df_fold[pred_cols].mean(axis=1)\n",
    "    auc_simple_avg = roc_auc_score(y_val_fold, blended_df_fold['simple_avg_fold_'+str(fold)])\n",
    "    auc_dict[\"Simple_Averaging\"].append(auc_simple_avg)\n",
    "\n",
    "    # Rank averaging\n",
    "    blended_df_fold['rank_avg_fold_'+str(fold)] = blended_df_fold[pred_cols].rank().mean(axis=1)\n",
    "    auc_rank_avg = roc_auc_score(y_val_fold, blended_df_fold['rank_avg_fold_'+str(fold)])\n",
    "    auc_dict[\"Rank_Averaging\"].append(auc_rank_avg)   \n",
    "\n",
    "# Calculate mean AUC for each method\n",
    "for method in auc_dict:\n",
    "    auc_dict[method] = np.mean(auc_dict[method])\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "auc_df = pd.DataFrame.from_dict(auc_dict, orient='index', columns=['Mean_AUC'])\n",
    "\n",
    "clear_output()\n",
    "auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1dd5b277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductID', 'Type', 'AirtemperatureK', 'ProcesstemperatureK',\n",
       "       'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'TWF', 'HDF', 'PWF',\n",
       "       'OSF', 'Temp_Diff', 'Failure_Summary', 'AirtemperatureKSquared',\n",
       "       'AirtemperatureKCubed', 'AirtemperatureKLog',\n",
       "       'ProcesstemperatureKSquared', 'ProcesstemperatureKCubed',\n",
       "       'ProcesstemperatureKLog', 'RotationalspeedrpmSquared',\n",
       "       'RotationalspeedrpmCubed', 'RotationalspeedrpmLog', 'TorqueNmSquared',\n",
       "       'TorqueNmCubed', 'TorqueNmLog', 'ToolwearminSquared',\n",
       "       'ToolwearminCubed', 'ToolwearminLog'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_fold.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a441b57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_valid_pred_fold_14</th>\n",
       "      <th>xgb_valid_pred_fold_14</th>\n",
       "      <th>cb_valid_pred_fold_14</th>\n",
       "      <th>diff_evolution_fold_14</th>\n",
       "      <th>weighted_avg_fold_14</th>\n",
       "      <th>simple_avg_fold_14</th>\n",
       "      <th>rank_avg_fold_14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.004540</td>\n",
       "      <td>0.003426</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>5918.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>8752.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.004962</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.002186</td>\n",
       "      <td>4300.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.004957</td>\n",
       "      <td>0.001111</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>9913.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.001082</td>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>14010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   lgbm_valid_pred_fold_14  xgb_valid_pred_fold_14  cb_valid_pred_fold_14  \\\n",
       "0                 0.000652                0.004962               0.000965   \n",
       "1                 0.000624                0.005025               0.001006   \n",
       "2                 0.000658                0.004962               0.000939   \n",
       "3                 0.000934                0.004957               0.001111   \n",
       "4                 0.001077                0.005134               0.001082   \n",
       "\n",
       "   diff_evolution_fold_14  weighted_avg_fold_14  simple_avg_fold_14  \\\n",
       "0                0.004540              0.003426            0.002193   \n",
       "1                0.004598              0.003479            0.002219   \n",
       "2                0.004538              0.003417            0.002186   \n",
       "3                0.004555              0.003481            0.002334   \n",
       "4                0.004717              0.003584            0.002431   \n",
       "\n",
       "   rank_avg_fold_14  \n",
       "0       5918.666667  \n",
       "1       8752.000000  \n",
       "2       4300.666667  \n",
       "3       9913.666667  \n",
       "4      14010.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blended_df_fold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39b3a15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02482228, 0.61753653, 0.35764119])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aedbd73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03514297, 0.89709319, 0.06776384])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_weights_de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9d638814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ProductID', 'Type', 'AirtemperatureK', 'ProcesstemperatureK',\n",
       "       'Rotationalspeedrpm', 'TorqueNm', 'Toolwearmin', 'TWF', 'HDF', 'PWF',\n",
       "       'OSF', 'RNF'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "024b0509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: lgbm on entire data\n",
      "Training: xgb on entire data\n",
      "Training: cb on entire data\n",
      "\n",
      "Training completed for all 3 models\n",
      "CPU times: total: 53min 12s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# First apply the custom features to your data\n",
    "custom_feats = CustomFeats()\n",
    "X = custom_feats.fit_transform(X)\n",
    "\n",
    "# replacing outliers\n",
    "# X = replace_outliers(X)  \n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "# Train each model on the full training set\n",
    "optimized_base_models = []\n",
    "for model_pipe in model_pipes:\n",
    "    model = list(model_pipe.named_steps.keys())[1]\n",
    "    print(f'Training: {model} on entire data')  \n",
    "    model_pipe.fit(X, y)\n",
    "    \n",
    "    # Getting the name of the model        \n",
    "    model_name = model+'_trained_on_entire_data'\n",
    "    \n",
    "    # Calibrate the model using cross validation\n",
    "    calibrator = CalibratedClassifierCV(model_pipe, cv=5, method='sigmoid')\n",
    "    calibrator.fit(X, y)\n",
    "    \n",
    "    optimized_base_models.append((model_name, calibrator))\n",
    "    \n",
    "print(f'\\nTraining completed for all {len(optimized_base_models)} models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1efaea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optimized_base_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07d734d",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 20px; color: #1192AA; text-align:left\">Predicting probabilities on Test Set:</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719c5e19",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">Using Blending:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60735e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['Product ID'] = test['Product ID'].str.slice(start=1).astype(float)\n",
    "# test['Type'] = type_enc.transform(test['Type'])\n",
    "test = clean_feature_names(test)\n",
    "\n",
    "# # Encoding Product ID\n",
    "# test = pd.merge(test, train_prob, on='ProductID', how='left')\n",
    "# test['prob'].fillna(Base_Prob, inplace=True)\n",
    "# test['prob'] = np.where(test['prob'] <= 0.15, Base_Prob, test['prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8186f5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_features:\n",
    "    test[col] = test[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fa00b854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for model lgbm_trained_on_entire_data\n",
      "Predicting for model xgb_trained_on_entire_data\n",
      "Predicting for model cb_trained_on_entire_data\n",
      "CPU times: total: 42.1 s\n",
      "Wall time: 2.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = custom_feats.transform(test)\n",
    "# test = replace_outliers(test)\n",
    "\n",
    "# Initialize a DataFrame to store test set predictions\n",
    "test_preds = pd.DataFrame(data={'id' : test.id})\n",
    "\n",
    "# Calculate test set predictions for each model\n",
    "for model_name, calibrator in optimized_base_models:\n",
    "    print(f'Predicting for model {model_name}')\n",
    "    test_preds[model_name] = calibrator.predict_proba(test)[:,1]\n",
    "\n",
    "pred_cols = [col for col in test_preds.columns if col != 'id']\n",
    "\n",
    "# Apply the best method to combine the predictions\n",
    "if auc_df.idxmax().values[0] == \"Weighted_Averaging\":\n",
    "    # Calculate the weighted average of the test set predictions\n",
    "    # Use the same weights as the ones that gave the best AUC on the validation set\n",
    "    test_preds['Machine failure'] = np.average(test_preds[pred_cols].values, axis=1, weights=optimal_weights)\n",
    "elif auc_df.idxmax().values[0] == \"Simple_Averaging\":\n",
    "    # Calculate the simple average of the test set predictions\n",
    "    test_preds['Machine failure'] = test_preds[pred_cols].mean(axis=1)\n",
    "elif auc_df.idxmax().values[0] == \"Rank_Averaging\":\n",
    "#     Calculate the rank average of the test set predictions\n",
    "    test_preds['Machine failure'] = test_preds[pred_cols].rank().mean(axis=1)    \n",
    "elif auc_df.idxmax().values[0] == \"Differential_Evolution\":\n",
    "#     Calculate the rank average of the test set predictions\n",
    "    test_preds['Machine failure'] = np.average(test_preds[pred_cols].values, axis=1, weights=optimal_weights_de)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "519281d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lgbm_trained_on_entire_data</th>\n",
       "      <th>xgb_trained_on_entire_data</th>\n",
       "      <th>cb_trained_on_entire_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.002962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003275</td>\n",
       "      <td>0.002683</td>\n",
       "      <td>0.002959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.002948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90949</th>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90950</th>\n",
       "      <td>0.003281</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90951</th>\n",
       "      <td>0.003323</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.003003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90952</th>\n",
       "      <td>0.003278</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>0.003168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90953</th>\n",
       "      <td>0.003299</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90954 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       lgbm_trained_on_entire_data  xgb_trained_on_entire_data  \\\n",
       "0                         0.003288                    0.002687   \n",
       "1                         0.003307                    0.002686   \n",
       "2                         0.003275                    0.002683   \n",
       "3                         0.003318                    0.002699   \n",
       "4                         0.003300                    0.002687   \n",
       "...                            ...                         ...   \n",
       "90949                     0.003294                    0.002687   \n",
       "90950                     0.003281                    0.002764   \n",
       "90951                     0.003323                    0.002693   \n",
       "90952                     0.003278                    0.003391   \n",
       "90953                     0.003299                    0.002687   \n",
       "\n",
       "       cb_trained_on_entire_data  \n",
       "0                       0.002959  \n",
       "1                       0.002962  \n",
       "2                       0.002959  \n",
       "3                       0.002948  \n",
       "4                       0.002953  \n",
       "...                          ...  \n",
       "90949                   0.002961  \n",
       "90950                   0.002978  \n",
       "90951                   0.003003  \n",
       "90952                   0.003168  \n",
       "90953                   0.002975  \n",
       "\n",
       "[90954 rows x 3 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds[pred_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55f3af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds[['id', 'Machine failure']].to_csv('blend_robust_w8_avg_calibrated_fmin_6mdls_catboostEnc_cb_lgbm_tuned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84fe98a",
   "metadata": {},
   "source": [
    "<h2 style = \"font-family: Georgia;font-weight: bold; font-size: 15px; color: #1192AA; text-align:left\">Using Stacking:</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3727a0f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
